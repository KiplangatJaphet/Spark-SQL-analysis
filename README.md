
# International Debt Analysis with Apache Spark SQL

## Project Overview

This project performs large-scale analysis of international debt data using **Apache Spark (PySpark)** and **Spark SQL**. The dataset, stored as a CSV file, contains country-level debt indicators and financial statistics.

The objective of this project is to demonstrate practical big data processing skills, distributed computation, and analytical querying using Spark.

This project showcases my ability to:

* Work with structured financial datasets
* Use Spark DataFrames and Spark SQL effectively
* Perform aggregations and analytical queries
* Extract meaningful insights from real-world economic data


## ðŸ›  Tech Stack

* **Python**
* **Apache Spark**
* **Spark SQL**
* **Jupyter Notebook**
* **CSV Data Processing**


**Dataset Description**
The dataset includes:
* Country Name
* Country Code
* Debt Indicator Name
* Indicator Code
* Debt Amount (USD)


**Key Business Questions Answered**
1. What is the total amount of debt owed by all countries in the dataset?
2. How many distinct countries are recorded in the dataset?
3. What are the distinct types of indicators and what do they represent?
4. Which country has the highest total debt and how much does it owe?
5. What is the average debt across different debt indiactors?
6. Which country has made the highest number of principal repayments?
7. What is the most common debt indicator across all countries?
8. Identify any other key debt trends and summarizeÂ yourÂ findings.
   

**Analytical Techniques Used**

* Schema inference and data validation
* DataFrame transformations
* SQL-style querying with Spark SQL
* Aggregations (`SUM`, `AVG`, `COUNT`)
* Grouping and ordering results
* Identifying top-N values
* Performance-efficient distributed computation



